{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a1fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dea99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('data/filtered_annotations.pkl', 'rb') as file:\n",
    "    annotations = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595f44ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 187250/187250 [04:21<00:00, 715.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46813/46813 [01:04<00:00, 731.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from probe_dataset import *\n",
    "split = 0.8\n",
    "annotations.sort(key = lambda ant : ant['f_name'])\n",
    "train_ants = annotations[:int(len(annotations)*split)]\n",
    "test_ants = annotations[int(len(annotations)*split):]\n",
    "\n",
    "keywords = ['territory', 'cut', 'sente', 'shape', 'moyo',\n",
    "            'ko', 'invasion', 'influence', 'wall', 'eye']\n",
    "train_dataset = SPBoWDataset(train_ants, keywords)\n",
    "test_dataset = SPBoWDataset(test_ants, keywords)\n",
    "\n",
    "train_dataset = load_to_memory(train_dataset)\n",
    "test_dataset = load_to_memory(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039c8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "go_model = load_go_model_from_ckpt('model_ckpt.pth.tar', rm_prefix=True)\n",
    "feat_models = [CutModel(go_model, i).cuda() for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe71145",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_n_channels = [8, 64, 64, 64, 48, 48, 32, 32]\n",
    "layer_dims = [n*19*19 for n in layer_n_channels]\n",
    "def init_probe_model(layer):\n",
    "    return nn.Linear(layer_dims[layer], len(keywords)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e0afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_experiment import ProbeExperiment\n",
    "exp = ProbeExperiment(train_dataset, test_dataset, keywords)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6098b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] epoch 0 loss 0.188911, new best\n",
      "[LOG] epoch 1 loss 0.169074, new best\n",
      "[LOG] epoch 2 loss 0.164735, new best\n",
      "[LOG] epoch 3 loss 0.163185, new best\n",
      "[LOG] epoch 4 loss 0.162426, new best\n",
      "[LOG] epoch 5 loss 0.161958, new best\n",
      "[LOG] epoch 6 loss 0.161613, new best\n",
      "[LOG] epoch 7 loss 0.161333, new best\n",
      "[LOG] epoch 8 loss 0.161093, new best\n",
      "[LOG] epoch 9 loss 0.160878, new best\n",
      "[LOG] epoch 0 loss 0.300985, new best\n",
      "[LOG] epoch 1 loss 0.221930, new best\n",
      "[LOG] epoch 2 loss 0.194279, new best\n",
      "[LOG] epoch 3 loss 0.181597, new best\n",
      "[LOG] epoch 4 loss 0.174836, new best\n",
      "[LOG] epoch 5 loss 0.170865, new best\n",
      "[LOG] epoch 6 loss 0.168366, new best\n",
      "[LOG] epoch 7 loss 0.166707, new best\n",
      "[LOG] epoch 8 loss 0.165556, new best\n",
      "[LOG] epoch 9 loss 0.164730, new best\n",
      "[LOG] epoch 0 loss 0.473753, new best\n",
      "[LOG] epoch 1 loss 0.362813, new best\n",
      "[LOG] epoch 2 loss 0.300890, new best\n",
      "[LOG] epoch 3 loss 0.263241, new best\n",
      "[LOG] epoch 4 loss 0.238736, new best\n",
      "[LOG] epoch 5 loss 0.221922, new best\n",
      "[LOG] epoch 6 loss 0.209900, new best\n",
      "[LOG] epoch 7 loss 0.201016, new best\n",
      "[LOG] epoch 8 loss 0.194275, new best\n",
      "[LOG] epoch 9 loss 0.189046, new best\n",
      "[LOG] epoch 0 loss 0.609695, new best\n",
      "[LOG] epoch 1 loss 0.543287, new best\n",
      "[LOG] epoch 2 loss 0.489571, new best\n",
      "[LOG] epoch 3 loss 0.445804, new best\n",
      "[LOG] epoch 4 loss 0.409845, new best\n",
      "[LOG] epoch 5 loss 0.380043, new best\n",
      "[LOG] epoch 6 loss 0.355127, new best\n",
      "[LOG] epoch 7 loss 0.334120, new best\n",
      "[LOG] epoch 8 loss 0.316265, new best\n",
      "[LOG] epoch 9 loss 0.300974, new best\n",
      "[LOG] epoch 0 loss 0.666783, new best\n",
      "[LOG] epoch 1 loss 0.639040, new best\n",
      "[LOG] epoch 2 loss 0.613249, new best\n",
      "[LOG] epoch 3 loss 0.589263, new best\n",
      "[LOG] epoch 4 loss 0.566944, new best\n",
      "[LOG] epoch 5 loss 0.546165, new best\n",
      "[LOG] epoch 6 loss 0.526806, new best\n",
      "[LOG] epoch 7 loss 0.508757, new best\n",
      "[LOG] epoch 8 loss 0.491916, new best\n",
      "[LOG] epoch 9 loss 0.476187, new best\n",
      "[LOG] epoch 0 loss 0.684557, new best\n",
      "[LOG] epoch 1 loss 0.675635, new best\n",
      "[LOG] epoch 2 loss 0.666907, new best\n",
      "[LOG] epoch 3 loss 0.658369, new best\n",
      "[LOG] epoch 4 loss 0.650016, new best\n",
      "[LOG] epoch 5 loss 0.641843, new best\n",
      "[LOG] epoch 6 loss 0.633848, new best\n",
      "[LOG] epoch 7 loss 0.626026, new best\n",
      "[LOG] epoch 8 loss 0.618372, new best\n",
      "[LOG] epoch 9 loss 0.610884, new best\n",
      "[LOG] epoch 0 loss 0.690573, new best\n",
      "[LOG] epoch 1 loss 0.687534, new best\n",
      "[LOG] epoch 2 loss 0.684516, new best\n",
      "[LOG] epoch 3 loss 0.681521, new best\n",
      "[LOG] epoch 4 loss 0.678547, new best\n",
      "[LOG] epoch 5 loss 0.675595, new best\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0b9ed05c847d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m                \u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobe_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                'write_log':True, 'save_ckpt':False}\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'optim_exp/%s_layer%d_lr%f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\go-probe\\probe_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, trial_name, feat_model, probe_model, configs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\go-probe\\probe_experiment.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(feat_model, probe_model, loader, criterion, optimizer, logger, epoch)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobe_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lrs = [0.1, 0.03, 0.01, 0.003, 0.001, 0.0003, 0.0001]\n",
    "k = 7\n",
    "optim = torch.optim.SGD\n",
    "name = 'SGD'\n",
    "feat_model = feat_models[k]\n",
    "\n",
    "for lr in lrs:\n",
    "    probe_model = init_probe_model(k)\n",
    "    config = {'num_epochs':10, 'batch_size':512,\n",
    "               'criterion':criterion,\n",
    "               'optimizer':optim(probe_model.parameters(), lr=lr),\n",
    "               'write_log':True, 'save_ckpt':False}\n",
    "    exp.run('optim_exp/%s_layer%d_lr%f' % (name, k, lr), feat_model, probe_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e385fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] epoch 0 loss 0.229096, new best\n",
      "[LOG] epoch 1 loss 0.276639\n",
      "[LOG] epoch 2 loss 0.263926\n",
      "[LOG] epoch 3 loss 0.273811\n",
      "[LOG] epoch 4 loss 0.289331\n",
      "[LOG] epoch 5 loss 0.294964\n",
      "[LOG] epoch 6 loss 0.309539\n",
      "[LOG] epoch 7 loss 0.304523\n",
      "[LOG] epoch 8 loss 0.308369\n",
      "[LOG] epoch 9 loss 0.318987\n",
      "[LOG] epoch 0 loss 0.170148, new best\n",
      "[LOG] epoch 1 loss 0.178172\n",
      "[LOG] epoch 2 loss 0.185362\n",
      "[LOG] epoch 3 loss 0.191040\n",
      "[LOG] epoch 4 loss 0.198960\n",
      "[LOG] epoch 5 loss 0.201314\n",
      "[LOG] epoch 6 loss 0.206242\n",
      "[LOG] epoch 7 loss 0.210041\n",
      "[LOG] epoch 8 loss 0.213741\n",
      "[LOG] epoch 9 loss 0.215433\n",
      "[LOG] epoch 0 loss 0.158996, new best\n",
      "[LOG] epoch 1 loss 0.161707\n",
      "[LOG] epoch 2 loss 0.167029\n",
      "[LOG] epoch 3 loss 0.168161\n",
      "[LOG] epoch 4 loss 0.170790\n",
      "[LOG] epoch 5 loss 0.173142\n",
      "[LOG] epoch 6 loss 0.177294\n",
      "[LOG] epoch 7 loss 0.178361\n",
      "[LOG] epoch 8 loss 0.180899\n",
      "[LOG] epoch 9 loss 0.183245\n",
      "[LOG] epoch 0 loss 0.156678, new best\n",
      "[LOG] epoch 1 loss 0.157287\n",
      "[LOG] epoch 2 loss 0.158128\n",
      "[LOG] epoch 3 loss 0.159249\n",
      "[LOG] epoch 4 loss 0.159399\n",
      "[LOG] epoch 5 loss 0.160645\n",
      "[LOG] epoch 6 loss 0.161757\n",
      "[LOG] epoch 7 loss 0.162518\n",
      "[LOG] epoch 8 loss 0.163460\n",
      "[LOG] epoch 9 loss 0.164572\n",
      "[LOG] epoch 0 loss 0.157548, new best\n",
      "[LOG] epoch 1 loss 0.156615, new best\n",
      "[LOG] epoch 2 loss 0.156419, new best\n",
      "[LOG] epoch 3 loss 0.156404, new best\n",
      "[LOG] epoch 4 loss 0.156592\n",
      "[LOG] epoch 5 loss 0.156783\n",
      "[LOG] epoch 6 loss 0.157002\n",
      "[LOG] epoch 7 loss 0.157401\n",
      "[LOG] epoch 8 loss 0.157785\n",
      "[LOG] epoch 9 loss 0.158089\n",
      "[LOG] epoch 0 loss 0.160642, new best\n",
      "[LOG] epoch 1 loss 0.158512, new best\n",
      "[LOG] epoch 2 loss 0.157569, new best\n",
      "[LOG] epoch 3 loss 0.157043, new best\n",
      "[LOG] epoch 4 loss 0.156760, new best\n",
      "[LOG] epoch 5 loss 0.156555, new best\n",
      "[LOG] epoch 6 loss 0.156387, new best\n",
      "[LOG] epoch 7 loss 0.156314, new best\n",
      "[LOG] epoch 8 loss 0.156301, new best\n",
      "[LOG] epoch 9 loss 0.156239, new best\n",
      "[LOG] epoch 0 loss 0.177560, new best\n",
      "[LOG] epoch 1 loss 0.162847, new best\n",
      "[LOG] epoch 2 loss 0.160599, new best\n",
      "[LOG] epoch 3 loss 0.159528, new best\n",
      "[LOG] epoch 4 loss 0.158791, new best\n",
      "[LOG] epoch 5 loss 0.158253, new best\n",
      "[LOG] epoch 6 loss 0.157844, new best\n",
      "[LOG] epoch 7 loss 0.157525, new best\n",
      "[LOG] epoch 8 loss 0.157278, new best\n",
      "[LOG] epoch 9 loss 0.157069, new best\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.1, 0.03, 0.01, 0.003, 0.001, 0.0003, 0.0001]\n",
    "k = 7\n",
    "optim = torch.optim.Adam\n",
    "name = 'Adam'\n",
    "feat_model = feat_models[k]\n",
    "\n",
    "for lr in lrs:\n",
    "    probe_model = init_probe_model(k)\n",
    "    config = {'num_epochs':10, 'batch_size':512,\n",
    "               'criterion':criterion,\n",
    "               'optimizer':optim(probe_model.parameters(), lr=lr),\n",
    "               'write_log':True, 'save_ckpt':False}\n",
    "    exp.run('optim_exp/%s_layer%d_lr%f' % (name, k, lr), feat_model, probe_model, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
